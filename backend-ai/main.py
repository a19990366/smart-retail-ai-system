from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import os
from sqlalchemy import create_engine, text
from sentence_transformers import SentenceTransformer

app = FastAPI()

# å®šç¾©è«‹æ±‚æ ¼å¼ (é€™å°±æ˜¯ DTO)
class PredictionRequest(BaseModel):
    product_id: str
    days: int = 7  # é è¨­é æ¸¬æœªä¾† 7 å¤©

# å…¨åŸŸè®Šæ•¸ç”¨ä¾†å¿«å–æ¨¡å‹
models = {}

def load_model(product_id: str):
    """
    å‹•æ…‹è¼‰å…¥æ¨¡å‹ï¼šå¦‚æœè¨˜æ†¶é«”æ²’æœ‰ï¼Œå°±å»ç¡¬ç¢Ÿè®€å– .pkl
    """
    if product_id in models:
        return models[product_id]
    
    model_path = f"models/{product_id}.pkl"
    if not os.path.exists(model_path):
        return None
    
    print(f"ğŸ“¥ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {model_path}")
    model = joblib.load(model_path)
    models[product_id] = model
    return model

@app.get("/")
def health_check():
    return {"status": "ok", "service": "AI Core"}

@app.post("/predict")
def predict_sales(request: PredictionRequest):
    # 1. è¼‰å…¥æ¨¡å‹
    model = load_model(request.product_id)
    if not model:
        raise HTTPException(status_code=404, detail=f"Model for {request.product_id} not found. Please train it first.")

    # 2. å»ºç«‹æœªä¾†æ—¥æœŸ (Prophet çš„æ¨™æº–ç”¨æ³•)
    future = model.make_future_dataframe(periods=request.days)
    
    # 3. é€²è¡Œé æ¸¬
    forecast = model.predict(future)
    
    # 4. æ•´ç†å›å‚³çµæœ (åªå›å‚³æœªä¾†çš„é æ¸¬å€¼)
    # å–æœ€å¾Œ N å¤©çš„è³‡æ–™
    result = forecast[['ds', 'yhat']].tail(request.days)
    
    # è½‰æˆ JSON æ ¼å¼å›å‚³
    response = []
    for _, row in result.iterrows():
        response.append({
            "date": row['ds'].strftime('%Y-%m-%d'),
            "predicted_sales": round(row['yhat'], 2)
        })
        
    return {
        "product_id": request.product_id,
        "forecast": response
    }

# === æ–°å¢ï¼šRAG ç›¸é—œè®Šæ•¸ ===
# åˆå§‹åŒ– Embedding æ¨¡å‹ (æœƒè‡ªå‹•ä¸‹è¼‰æˆ–è®€å– cache)
rag_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# è³‡æ–™åº«é€£ç·š (è¨˜å¾—åŠ é€™æ®µ)
DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:000@localhost:5432/retail_ops')
engine = create_engine(DB_URL)

class QuestionRequest(BaseModel):
    question: str

@app.post("/rag/ask")
def ask_question(request: QuestionRequest):
    """
    RAG æœå°‹ä»‹é¢ï¼š
    1. æŠŠä½¿ç”¨è€…çš„å•é¡Œè½‰æˆå‘é‡
    2. å»è³‡æ–™åº«æ‰¾æœ€åƒçš„çŸ¥è­˜
    3. å›å‚³æ‰¾åˆ°çš„çŸ¥è­˜ (ç›®å‰å…ˆä¸åš LLM ç”Ÿæˆï¼Œå…ˆåšæœå°‹)
    """
    # 1. å°‡å•é¡Œè½‰æˆå‘é‡
    query_vec = rag_model.encode(request.question, normalize_embeddings=True)
    
    # 2. å»è³‡æ–™åº«æœå°‹ (é€™æ˜¯ pgvector æœ€å¼·çš„åŠŸèƒ½ï¼š<-> ä»£è¡¨æ­å¹¾é‡Œå¾—è·é›¢)
    # æˆ‘å€‘æ‰¾æœ€æ¥è¿‘çš„ 1 ç­†è³‡æ–™
    search_sql = text("""
        SELECT content, embedding <-> :query_vec AS distance
        FROM product_embeddings
        ORDER BY distance ASC
        LIMIT 1;
    """)
    
    # åŸ·è¡Œ SQL
    with engine.connect() as conn:
        # ä½¿ç”¨ .tolist() ç¢ºä¿è½‰æˆç´” Python listï¼Œå†è½‰å­—ä¸²
        result = conn.execute(search_sql, {"query_vec": str(query_vec.tolist())}).fetchone()
        
    if not result:
        return {"answer": "æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚"}
        
    # 3. å›å‚³çµæœ
    best_match_content = result[0]
    distance = result[1]
    
    # å¦‚æœè·é›¢å¤ªé  (ä»£è¡¨å•é¡Œè·ŸçŸ¥è­˜åº«ç„¡é—œ)ï¼Œå¯ä»¥è¨­å€‹é–€æª»
    if distance > 1.5: # é–€æª»å€¼å¯ä»¥æ¸¬è©¦èª¿æ•´
         return {"answer": "é€™å€‹å•é¡Œè¶…å‡ºæˆ‘çš„çŸ¥è­˜ç¯„åœã€‚", "debug_content": best_match_content}

    return {
        "question": request.question,
        "retrieved_policy": best_match_content,
        "similarity_score": round(distance, 4)
    }